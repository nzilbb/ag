<!DOCTYPE html>


<!--
 | Generated by Apache Maven Doxia Site Renderer 2.0.0 from src/site/markdown/index.md.vm at 2025-09-19
 | Rendered using Apache Maven Fluido Skin 2.1.0
-->
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="generator" content="Apache Maven Doxia Site Renderer 2.0.0" />
    <title>nzilbb.formatter.elan (1.8.6) – nzilbb.formatter.elan</title>
    <link rel="stylesheet" href="./css/apache-maven-fluido-2.1.0.min.css" />
    <link rel="stylesheet" href="./css/site.css" />
    <link rel="stylesheet" href="./css/print.css" media="print" />
    <script src="./js/apache-maven-fluido-2.1.0.min.js"></script>
  </head>
  <body>
    <div class="container-fluid container-fluid-top">
      <header>
        <div id="banner">
          <div class="pull-left"><div id="bannerLeft"><h1><a href="https://nzilbb.github.io/ag/"><img src="https://nzilbb.github.io/ag/images/labbcat.png" /> nzilbb.formatter.elan</a></h1></div></div>
          <div class="pull-right"><div id="bannerRight"><h1><a href="https://www.canterbury.ac.nz/nzilbb/"><img src="https://nzilbb.github.io/ag/images/nzilbb.svg" /></a></h1></div></div>
          <div class="clear"><hr/></div>
        </div>

        <div id="breadcrumbs">
          <ul class="breadcrumb">
        <li id="publishDate">Last Published: 2025-09-19<span class="divider">|</span>
</li>
          <li id="projectVersion">Version: 1.8.6<span class="divider">|</span></li>
      <li><a href="../../index.html">Annotation Graphs</a><span class="divider">/</span></li>
      <li><a href="../index.html">Formatters</a><span class="divider">/</span></li>
    <li class="active">nzilbb.formatter.elan (1.8.6)</li>
        <li class="pull-right"><span class="divider">|</span>
<a href="http://dx.doi.org/10.1016/j.csl.2017.01.004">Fromont (2017)</a></li>
        <li class="pull-right"><span class="divider">|</span>
<a href="https://labbcat.canterbury.ac.nz/">LaBB-CAT</a></li>
        <li class="pull-right"><a href="http://creativecommons.org/licenses/by-sa/2.0/">CC-BY-SA</a></li>
          </ul>
        </div>
      </header>
      <div class="row-fluid">
        <header id="leftColumn" class="span2">
          <nav class="well sidebar-nav">
  <ul class="nav nav-list">
   <li class="nav-header">nzilbb.formatter.elan</li>
    <li><a href="https://raw.githubusercontent.com/nzilbb/ag/refs/heads/main/bin/nzilbb.formatter.elan.jar">Download</a></li>
  </ul>
          </nav>
          <div class="well sidebar-nav">
            <div id="poweredBy">
              <div class="clear"></div>
              <div class="clear"></div>
<a href="https://maven.apache.org/" class="builtBy" target="_blank"><img class="builtBy" alt="Built by Maven" src="./images/logos/maven-feather.png" /></a>
            </div>
          </div>
        </header>
        <main id="bodyColumn" class="span10">
<section><a id="nzilbb.formatter.elan_.281.8.6.29"></a>
<h1>nzilbb.formatter.elan (1.8.6)</h1>
<p>Serializer/Deserializer for ELAN files.</p>
<p>ELAN (EUDICO Linguistic Annotator -
<a href="http://www.lat-mpi.eu/tools/elan/" class="externalLink">http://www.lat-mpi.eu/tools/elan/</a>) is a tier-based media annotation
tool developed by the Max Planck Institute for Psycholinguistics,
which can be used both for orthographic transcription, and also
extensive annotation on different tiers. It can be used to annotate
multiple video files, and/or an audio file.</p>
<p>For parsing ELAN (.eaf) files the general assumption is that there is
one tier per speaker that includes orthographic transcription of their
speech (there can be other non-transcript annotation tiers).</p>
<section><a id="Tier_to_Layer_correspondences"></a>
<h2 id="mapping">Tier to Layer correspondences</h2>

<p>When parsing an ELAN file, the general assumption is that each
TextGrid tier corresponds to an annotation layer, and before being
fully processed, correspondences between tiers and layers need to be
specified. The formatter tries to select sensible defaults for these
correspondences; as a general rule, if the name of the tier matches
the name of an existing annotation layer, then the tier will be mapped
to the layer with the same name.</p>
<p>If no automatic correspondence is obvious, the formatter assumes that
the tier contains the transcript of the speech of one speaker;
the tier is mapped to the &#x201c;utterance&#x201d; layer, and the tier's
<em>Participant</em> attribute  (or the tier name if the <em>Participant</em>
attribute is blank) is used as the speaker's name/ID.</p>
<p>While determining default tier-to-layer mappings, the following
special cases also apply:</p>
<ul>

<li>tiers named <em>lines</em> or <em>utterances</em> are mapped to the <em>utterance</em> layer.</li>
<li>tiers named <em>speaker[s]</em>, <em>turn[s]</em>, or &#x201c;utterances&#x201d; are mapped to the
<em>turn</em> (speaker turn) layer.</li>
<li>tiers with names that include <em>word</em> are mapped to the <em>word</em> layer.</li>
</ul>
</section><section><a id="Meta-data"></a>
<h2 id="metadata">Meta-data</h2>

<p>The <em>Content Language</em> attribute of the tiers, if set, is used for
setting the transcript language.</p>
<p>The <em>AUTHOR</em> attribute of the transcript, if set, can be mapped to an
author/transcriber attribute layer.</p>
<p>The <em>DATE</em> attribute of the transcript, if set, can be mapped to an
date attribute layer.</p>
<p>If <code>PROPERTY</code> tags in the .eaf file's XML code include have a <code>NAME</code>
attribute that is prefixed <code>metadata:</code>, then the formatter will
attempt to parse the meta-data values into corresponding attribute
layers. For example:</p>
<ul>

<li><code>&lt;PROPERTY NAME=&quot;metadata:location&quot;&gt;Flores&lt;/PROPERTY&gt;</code> will map to
the <em>location</em> annotation layer by default, and create an annotation
labelled &#x201c;Flores&#x201d;.</li>
<li><code>&lt;PROPERTY NAME=&quot;metadata:Gender:Anne&quot;&gt;F&lt;/PROPERTY&gt;</code> will map
to the <em>Gender</em> participant annotation layer by default, and tag the
participant labelled &#x201c;Anne&#x201d; with an annotation labelled &#x201c;F&#x201d;.</li>
</ul>
</section><section><a id="Conventions_for_non-speech_annotations_within_the_transcript"></a>
<h2 id="conventions">Conventions for non-speech annotations within the transcript</h2>

<p>ELAN has no direct mechanism for marking non-speech annotations in their position within the transcript text.  However, LaBB-CAT supports the use of textual conventions in various ways to make certain annotations:</p>
<ul>

<li>To tag a word with its pronunciation, enter the pronunciation in
square brackets (with no spaces), directly following the word (i.e. with no
intervening space), e.g.:\
<code>&#x2026;this was at Wingatui[wIN@tui]&#x2026;</code></li>
<li>To tag a word with its full orthography (if the transcript doesn't
include it), enter the orthography (with no spaces) in round parentheses, directly
following the word (i.e. with no intervening space), e.g.:\
<code>&#x2026;I can't remem~(remember)&#x2026;</code></li>
<li>To insert a noise annotation within the text, enclose it in square
brackets (surrounded by spaces so it's not taken as a
pronunciation annotation), e.g.:\
<code>&#x2026;sometimes me [laughs] not always but sometimes&#x2026;</code></li>
<li>To insert a comment annotation within the text, enclose it in curly
braces (surrounded by spaces), e.g.:\
<code>&#x2026;beautifully warm {softly} but its&#x2026;</code></li>
<li>To tag a word as being in a different language, enter the code CS:
(for &#x2018;code switch&#x2019;) followed by the the ISO 639 3-letter code for
the language, in square brackets (with no spaces), directly following the word
(i.e. with no intervening space), e.g.:\
<code>&#x2026;me mud&#xe9; de New[CS:eng] Zealand[CS:eng] en 2004&#x2026;</code></li>
<li>For longer phrases, the code-switch tag can be placed immediately
before the first word and immediately after the last word, to mark
those and all intervening words as being in a different
language. e.g.:\
<code>&#x2026;has a certain [CS:fre]je ne sais quoi[CS:fre] I think&#x2026;</code></li>
</ul>
<p>The &#x2018;code switch&#x2019; example above is a specific case of a general coding
mechanism that can be used; any &#x2018;SALT style&#x2019; code can be used to tag a
word or phrase in this manner, as long as the code:</p>
<ul>

<li>is up to three uppercase ASCII letters long,</li>
<li>is followed by a colon followed by the annotation label with no
spaces (if the label is omitted, the layer ID is used for the
annotation label),</li>
<li>is enclosed in square brackets, and</li>
<li>has no white-space between it and the token it is tagging.</li>
</ul>
<p>If there are such codes in the transcript, then the code must be
assigned to an annotation layer before the transcript is processed; by
default a code will be mapped to an annotation layer with the same
name (either upper- or lower-case).</p>
<p>For example, given a word-tag layer called <em>ep</em>, the following
transcript would create an <em>ep</em>-layer tag labelled &#x201c;they&#x201d;:<br />
<code>And them[EP:they] found the frog.</code></p>
<p>During processing, any of these annotations will be extracted from the transcript text and inserted into corresponding LaBB-CAT layers.</p>
</section><section><a id="Configuration"></a>
<h2 id="configuration">Configuration</h2>

<p>The following parameters can be specified for the formatter:</p>
<dl>

<dt>ignoreBlankAnnotations</dt>
<dd>If <code>true</code>, annotations with no label are skipped.</dd>
<dt>useConventions</dt>
<dd><code>true</code> to use transcript conventions to identify comment, noise,
lexical and pronuncation annotations. (see <a href="#conventions">Transcription Conventions</a>).</dd>
<dt>commentLayer</dt>
<dd>ID of layer for commentary (see <a href="#conventions">Transcription Conventions</a>),</dd>
<dt>noiseLayer</dt>
<dd>ID of layer for background/non-verbal noises
(see <a href="#conventions">Transcription Conventions</a>).</dd>
<dt>lexicalLayer</dt>
<dd>ID of layer for lexical tags which identify to lexical item if the token orthography
doesn't do so (see <a href="#conventions">Transcription Conventions</a>).</dd>
<dt>pronounceLayer</dt>
<dd>ID of layer for manual pronunciation tags
(see <a href="#conventions">Transcription Conventions</a>).</dd>
<dt>authorLayer</dt>
<dd>ID of the transcript attribute layer for the name of transcriber
(see <a href="#metadata">Meta-data</a>).</dd>
<dt>dateLayer</dt>
<dd>ID of the transcript attribute layer for the document date (see <a href="#metadata">Meta-data</a>).</dd>
<dt>languageLayer</dt>
<dd>ID of the transcript attribute layer for the transcript language
(see <a href="#metadata">Meta-data</a>).</dd>
<dt>phraseLanguageLayer</dt>
<dd>ID of the aligned phrase layer for tagging groups of words as being
in a different language (see <a href="#conventions">Transcript Conventions</a>).</dd>
<dt>minimumTurnPauseLength</dt>
<dd>Minimum amount of time (in seconds) between two turns by the same
speaker, with no intervening speaker, for which the inter-turn
pausecounts as a turn change boundary. If the pause is shorter than
this, the turns are merged into one.</dd>
</dl></section></section>        </main>
      </div>
    </div>
    <hr/>
    <footer>
      <div class="container-fluid">
        <div class="row-fluid">
<a rel='license' href='http://creativecommons.org/licenses/by-sa/2.0/'><img alt='CC-BY-SA Creative Commons Licence ' src='/ag/images/cc-by-sa.svg' title='This work is licensed under a Creative Commons Attribution-ShareAlike 2.0 Generic License' /></a><a rel='author' href='https://www.canterbury.ac.nz/nzilbb/'><img src='/ag/images/nzilbb.svg' alt='Te Kāhui Roro Reo | The New Zealand Institute of Language, Brain and Behaviour' title='🄯 NZILBB'></a>
        </div>
      </div>
    </footer>
  </body>
</html>
